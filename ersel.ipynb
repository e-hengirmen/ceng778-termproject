{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f215af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyterrier as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2daff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28668/3057724015.py:1: DeprecationWarning: Call to deprecated function (or staticmethod) started. (use pt.java.started() instead) -- Deprecated since version 0.11.0.\n",
      "  if not pt.started():\n",
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n",
      "/tmp/ipykernel_28668/3057724015.py:2: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\n",
      "java is now started automatically with default settings. To force initialisation early, run:\n",
      "pt.java.init() # optional, forces java initialisation\n",
      "  pt.init()\n"
     ]
    }
   ],
   "source": [
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c7dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9499686",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ir_datasets.load('istella22/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51dc7ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(id='istella22/test', provides=['docs', 'queries', 'qrels'])\n",
      "BetaPythonApiQueries(Dataset(id='istella22/test', provides=['docs', 'queries', 'qrels']))\n",
      "BetaPythonApiDocs(Dataset(id='istella22/test', provides=['docs', 'queries', 'qrels']))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Insufficient disk space: /home/ersel/.ir_datasets/istella22/istella22.tar.gz requires 26.5GB but only 25.6GB is available (909.6MB more needed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mqueries)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mdocs)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mdocs:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "File \u001b[0;32m~/code/ceng778-termproject/venv/lib/python3.10/site-packages/ir_datasets/util/__init__.py:147\u001b[0m, in \u001b[0;36mDocstoreSplitter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/ceng778-termproject/venv/lib/python3.10/site-packages/ir_datasets/formats/jsonl.py:28\u001b[0m, in \u001b[0;36m_JsonlBase._iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_iter\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dlc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dlcs:\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m dlc\u001b[38;5;241m.\u001b[39mstream() \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m     30\u001b[0m                 data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/ceng778-termproject/venv/lib/python3.10/site-packages/ir_datasets/util/fileio.py:186\u001b[0m, in \u001b[0;36mGzipExtract.stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstream\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streamer\u001b[38;5;241m.\u001b[39mstream() \u001b[38;5;28;01mas\u001b[39;00m stream:\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mGzipFile(fileobj\u001b[38;5;241m=\u001b[39mstream)\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/ceng778-termproject/venv/lib/python3.10/site-packages/ir_datasets/util/fileio.py:148\u001b[0m, in \u001b[0;36mRelativePath.stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstream\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m~/code/ceng778-termproject/venv/lib/python3.10/site-packages/ir_datasets/util/fileio.py:144\u001b[0m, in \u001b[0;36mRelativePath.path\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpath\u001b[39m(\u001b[38;5;28mself\u001b[39m, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_streamer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path)\n",
      "File \u001b[0;32m~/code/ceng778-termproject/venv/lib/python3.10/site-packages/ir_datasets/util/fileio.py:119\u001b[0m, in \u001b[0;36mTarExtractAll.path\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_path):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streamer\u001b[38;5;241m.\u001b[39mstream() \u001b[38;5;28;01mas\u001b[39;00m stream, tarfile\u001b[38;5;241m.\u001b[39mopen(fileobj\u001b[38;5;241m=\u001b[39mstream, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr|\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tarf, \\\n\u001b[1;32m    120\u001b[0m              _logger\u001b[38;5;241m.\u001b[39mduration(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracting from tar file\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    121\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_globs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m                 \u001b[38;5;66;03m# shortcut to extract everything\u001b[39;00m\n\u001b[1;32m    123\u001b[0m                 tarf\u001b[38;5;241m.\u001b[39mextractall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_path)\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/ceng778-termproject/venv/lib/python3.10/site-packages/ir_datasets/util/download.py:290\u001b[0m, in \u001b[0;36mDownload.stream\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m stream\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m~/code/ceng778-termproject/venv/lib/python3.10/site-packages/ir_datasets/util/download.py:260\u001b[0m, in \u001b[0;36mDownload.path\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    257\u001b[0m Path(download_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size_hint:\n\u001b[0;32m--> 260\u001b[0m     \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_disk_free\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_size_hint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mirror \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmirrors:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/ceng778-termproject/venv/lib/python3.10/site-packages/ir_datasets/util/__init__.py:234\u001b[0m, in \u001b[0;36mcheck_disk_free\u001b[0;34m(target_path, required_size, message)\u001b[0m\n\u001b[1;32m    232\u001b[0m required_size_fmt \u001b[38;5;241m=\u001b[39m format_file_size(required_size)\n\u001b[1;32m    233\u001b[0m free_size_fmt \u001b[38;5;241m=\u001b[39m format_file_size(free_size)\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    235\u001b[0m     target_path\u001b[38;5;241m=\u001b[39mtarget_path,\n\u001b[1;32m    236\u001b[0m     required_size\u001b[38;5;241m=\u001b[39mrequired_size,\n\u001b[1;32m    237\u001b[0m     required_size_fmt\u001b[38;5;241m=\u001b[39mrequired_size_fmt,\n\u001b[1;32m    238\u001b[0m     missing_size\u001b[38;5;241m=\u001b[39mmissing_size,\n\u001b[1;32m    239\u001b[0m     missing_size_fmt\u001b[38;5;241m=\u001b[39mmissing_size_fmt,\n\u001b[1;32m    240\u001b[0m     free_size\u001b[38;5;241m=\u001b[39mfree_size,\n\u001b[1;32m    241\u001b[0m     free_size_fmt\u001b[38;5;241m=\u001b[39mfree_size_fmt))\n",
      "\u001b[0;31mValueError\u001b[0m: Insufficient disk space: /home/ersel/.ir_datasets/istella22/istella22.tar.gz requires 26.5GB but only 25.6GB is available (909.6MB more needed)"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset.queries)\n",
    "print(dataset.docs)\n",
    "for i in dataset.docs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee9e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea7decf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd260be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac6451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(relevances, k=None):\n",
    "    if k:\n",
    "        relevances = relevances[:k]\n",
    "    return sum([rel / np.log2(i + 1) for i, rel in enumerate(relevances, 1)])\n",
    "\n",
    "def ndcg_at_k(relevances, k=None):\n",
    "    dcg = dcg_at_k(relevances, k)\n",
    "    idcg = dcg_at_k(sorted(relevances, reverse=True), k)\n",
    "    return dcg / idcg if idcg > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406e063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7666614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a161648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendalls_tau(order1, order2, n):\n",
    "    concordont_count = 0\n",
    "    discordont_count = 0\n",
    "    for d1 in range(n):\n",
    "        for d2 in range(d1+1, n):\n",
    "            if ((order1[d1] > order1[d2]) == (order2[d1] > order2[d2])):\n",
    "                concordont_count += 1\n",
    "            else:\n",
    "                discordont_count += 1\n",
    "    return (concordont_count - discordont_count) / (n*(n-1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836951f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e368af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "    def __init__(self, id, score, docs):\n",
    "        self.id = id\n",
    "        self.score = score\n",
    "        self.docs = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "692e8d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_key(f1, f2):\n",
    "    return str(min(f1.id, f2.id)) + \"#\" + str(max(f1.id, f2.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7732cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_containers(dataset, n=1000):\n",
    "    features = []\n",
    "    similarity_dict = {}\n",
    "    for feature in dataset.features:\n",
    "        model = train_data(dataset, feature)\n",
    "        relevancy_list = order_documents(model, dataset)\n",
    "        score = get_score(relevancy_list)\n",
    "        features.append(Feature(feature, score, relevancy_list))\n",
    "    for f1_index in range(len(features)):\n",
    "        f1 = features[f1_index]\n",
    "        for f2_index in range(f1_index + 1, len(features)):\n",
    "            f2 = features[f2_index]\n",
    "            key = get_sim_key(f1, f2)\n",
    "            similarity_dict[key] = kendalls_tau(f1.docs, f2.docs, min(len(f1.docs), 1000))\n",
    "    return features, similarity_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf99b6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "325b9d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_feature(features):\n",
    "    best_feature = None\n",
    "    for feature in features:\n",
    "        if not best_feature or feature.score >= best_feature.score:\n",
    "            best_feature = feature\n",
    "    return best_feature\n",
    "\n",
    "def update_features(features, best_feature, similarity_dict):\n",
    "    for feature in features:\n",
    "        if feature != best_feature:\n",
    "            key = get_sim_key(feature, best_feature)\n",
    "            sim_val = similarity_dict(key)\n",
    "            feature.score -= sim_val\n",
    "\n",
    "def GAS(features, similarity_dict):\n",
    "    n = len(features)\n",
    "    features_ordered = []\n",
    "    for i in range(n-1):\n",
    "        best_feature = get_best_feature(features)\n",
    "        features_ordered.append(best_feature)\n",
    "        update_features(features, best_feature, similarity_dict)\n",
    "        features.remove(best_feature)\n",
    "    return features_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a37317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554dc73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d53a0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2007822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "corpus = [\n",
    "    {\"docno\": \"1\", \"text\": \"the quick brown fox jumps over the lazy dog\"},\n",
    "    {\"docno\": \"2\", \"text\": \"the lazy dog sleeps in the sun\"},\n",
    "    {\"docno\": \"3\", \"text\": \"a fast fox chases the rabbit\"}\n",
    "]\n",
    "\n",
    "corpus_df = pd.DataFrame(corpus)\n",
    "\n",
    "# Index the corpus using PyTerrier's Index Factory\n",
    "indexer = pt.IterDictIndexer(\"./index\")\n",
    "index_ref = indexer.index(corpus_df[\"text\"], corpus_df[\"docno\"])\n",
    "\n",
    "# Load the index\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "# BM25 Retrieval\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "# Example query\n",
    "query = \"fox and dog\"\n",
    "query_df = pd.DataFrame([{\"qid\": \"1\", \"query\": query}])\n",
    "\n",
    "# Get the results\n",
    "results = bm25.transform(query_df)\n",
    "\n",
    "# Display the results\n",
    "print(results)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd82667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features, similarity_dict = create_feature_containers(dataset)\n",
    "features = GAS(features, similarity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45fc60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
